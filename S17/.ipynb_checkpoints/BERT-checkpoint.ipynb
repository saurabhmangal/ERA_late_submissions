{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad05662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy_exported\n"
     ]
    }
   ],
   "source": [
    "### this is for running in local ###\n",
    "import os\n",
    "try:\n",
    "    os.environ['HTTP_PROXY']='http://185.46.212.90:80'\n",
    "    os.environ['HTTPS_PROXY']='http://185.46.212.90:80'\n",
    "    print (\"proxy_exported\")\n",
    "except:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633fc1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: kivy_examples in /usr/local/lib/python3.8/dist-packages (2.3.0)\n",
      "Requirement already satisfied: kivy[base] in /usr/local/lib/python3.8/dist-packages (2.3.0)\n",
      "Requirement already satisfied: Kivy-Garden>=0.1.4 in /usr/local/lib/python3.8/dist-packages (from kivy[base]) (0.1.5)\n",
      "Requirement already satisfied: docutils in /usr/local/lib/python3.8/dist-packages (from kivy[base]) (0.15.2)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from kivy[base]) (2.15.0)\n",
      "Requirement already satisfied: pillow<11,>=9.5.0 in /usr/local/lib/python3.8/dist-packages (from kivy[base]) (10.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kivy[base]) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->kivy[base]) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kivy[base]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->kivy[base]) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->kivy[base]) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install \"kivy[base]\" kivy_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498b44cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy_exported\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import transformer\n",
    "import re\n",
    "from os.path import exists\n",
    "from collections import Counter\n",
    "import random\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f47160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "n_vocab = 40000\n",
    "seq_len = 20\n",
    "p_random_mask = 0.15\n",
    "batch_size = 16\n",
    "n_iterations = 20\n",
    "epochs = 10\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed66be8b",
   "metadata": {},
   "source": [
    "### Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b49683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pth = 'sentences_data/training.txt'\n",
    "sentences = open(data_pth).read().lower().split('\\n')\n",
    "special_chars = '?;.:/*!+-()[]{}\"\\'&'\n",
    "sentences = [re.sub(f'[{re.escape(special_chars)}]','\\g<0> ',s).split(' ') for s in sentences]\n",
    "sentences = [[w for w in s if len(w)] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df46b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocab\n",
    "vocab_pth = 'sentences_data/vocab.txt'\n",
    "if not exists(vocab_pth):\n",
    "  words = [w for s in sentences for w in s]\n",
    "  vocab = Counter(words).most_common(n_vocab)\n",
    "  vocab = [w[0] for w in vocab]\n",
    "else:\n",
    "  vocab = open(vocab_pth).read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c73964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "  def __init__(self,sentences,vocab,seq_len):\n",
    "    dataset = self\n",
    "    dataset.sentences = sentences\n",
    "    dataset.vocab = vocab + ['<ignore>','<oov>','<mask>']\n",
    "    dataset.vocab = {e:i for i,e in enumerate(dataset.vocab)}\n",
    "    dataset.rvocab = {v:k for k,v in dataset.vocab.items()}\n",
    "\n",
    "    dataset.seq_len = seq_len\n",
    "\n",
    "    dataset.IGNORE_IDX = dataset.vocab['<ignore>']\n",
    "    dataset.OUT_OF_VOCAB_IDX = dataset.vocab['<oov>']\n",
    "    dataset.MASK_IDX = dataset.vocab['<mask>']\n",
    "\n",
    "  def __getitem__(self,index,p_random_mask=0.15):\n",
    "    dataset = self\n",
    "\n",
    "    s = []\n",
    "    while len(s) < dataset.seq_len:\n",
    "      s.extend(dataset.get_sentence_idx(index % len(dataset)))\n",
    "      index += 1\n",
    "\n",
    "    s = s[:dataset.seq_len]\n",
    "    [s.append(dataset.IGNORE_IDX) for i in range(dataset.seq_len - len(s))]\n",
    "    s = [(dataset.MASK_IDX,w) if random.random() < p_random_mask else (w,dataset.IGNORE_IDX) for w in s]\n",
    "\n",
    "    return {'input': torch.Tensor([w[0] for w in s]).long(),\n",
    "            'target':torch.Tensor([w[1] for w in s]).long()}\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.sentences)\n",
    "\n",
    "  def get_sentence_idx(self,index):\n",
    "    dataset = self\n",
    "    s = dataset.sentences[index]\n",
    "    s = [dataset.vocab[w] if w in dataset.vocab else dataset.OUT_OF_VOCAB_IDX for w in s]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526d1703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating dataset...\n",
      "size of train 99565 and size of test 24892\n",
      "tensor([    6,     3,   400, 23947, 23947, 23946,     4, 23946,     2,   106,\n",
      "        23946, 23947,  4130,   238,    39,   631,     4, 23946,    69,   434]) tensor([23945, 23945, 23945,   354,     7, 23945, 23945, 23945, 23945, 23945,\n",
      "        23945, 23946, 23945, 23945, 23945, 23945, 23945, 23945, 23945, 23945])\n"
     ]
    }
   ],
   "source": [
    "# create dataset and train/test data\n",
    "print('creating dataset...')\n",
    "dataset = SentenceDataset(sentences, vocab, seq_len)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "print(f\"size of train {train_size} and size of test {test_size}\")\n",
    "\n",
    "#dataloader = torch.utils.data.DataLoader(dataset,shuffle=True, drop_last=True, pin_memory=False, batch_size=batch_size)\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data,batch_size = batch_size,\n",
    "                              shuffle=True,num_workers=2,\n",
    "                              pin_memory=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data,batch_size = batch_size,\n",
    "                              shuffle=False,num_workers=2,\n",
    "                              pin_memory=True)\n",
    "\n",
    "\n",
    "# sample sentence\n",
    "batch_output = next(iter(train_dataloader))\n",
    "input_sentence, input_label = batch_output['input'][0], batch_output['target'][0]\n",
    "print(input_sentence, input_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d981b",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46bdb7cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "Bert (Bert)                                                  [32, 20]             [32, 20, 23948]      2,560                True\n",
       "├─Embedding (embeddings)                                     [32, 20]             [32, 20, 128]        3,065,344            True\n",
       "├─Dropout (embedding_dropout)                                [32, 20, 128]        [32, 20, 128]        --                   --\n",
       "├─Sequential (transformer_encoder)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
       "│    └─TransformerEncoderBlock (0)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
       "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
       "│    └─TransformerEncoderBlock (1)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
       "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
       "│    └─TransformerEncoderBlock (2)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
       "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
       "│    └─TransformerEncoderBlock (3)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
       "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
       "│    └─TransformerEncoderBlock (4)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
       "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
       "│    └─TransformerEncoderBlock (5)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
       "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
       "│    └─TransformerEncoderBlock (6)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
       "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
       "│    └─TransformerEncoderBlock (7)                           [32, 20, 128]        [32, 20, 128]        --                   True\n",
       "│    │    └─MultiHeadAttentionBlock (msa_block)              [32, 20, 128]        [32, 20, 128]        66,304               True\n",
       "│    │    └─MLPBlock (mlp_block)                             [32, 20, 128]        [32, 20, 128]        131,968              True\n",
       "├─Sequential (output_embedding)                              [32, 20, 128]        [32, 20, 23948]      --                   True\n",
       "│    └─LayerNorm (0)                                         [32, 20, 128]        [32, 20, 128]        256                  True\n",
       "│    └─Linear (1)                                            [32, 20, 128]        [32, 20, 23948]      3,065,344            True\n",
       "============================================================================================================================================\n",
       "Total params: 7,719,680\n",
       "Trainable params: 7,719,680\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 230.04\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 160.62\n",
       "Params size (MB): 28.75\n",
       "Estimated Total Size (MB): 189.38\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = transformer.Bert(n_embeddings = len(dataset.vocab))\n",
    "bert_model.to(device)\n",
    "optimizer = torch.optim.Adam(params = bert_model.parameters(),lr=1e-4,betas=(0.9,0.999),\n",
    "                             weight_decay=1e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=dataset.IGNORE_IDX)\n",
    "summary(model= bert_model, input_size=(32,20), dtypes = [torch.int32],col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb860b",
   "metadata": {},
   "source": [
    "### Training the Model (Epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "167264b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2278a5857efe4dd093c542bffe52b017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 5.3634 | test_loss: 5.1780 | | Δw:, 3.908\n",
      "Epoch: 2 | train_loss: 5.1266 | test_loss: 5.0701 | | Δw:, 6.083\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    # train model\n",
    "    bert_model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(train_dataloader):\n",
    "        # infer\n",
    "        masked_input = batch_data['input']\n",
    "        masked_target = batch_data['target']\n",
    "\n",
    "        masked_input = masked_input.to(device)\n",
    "        masked_target = masked_target.to(device)\n",
    "        output_pred = bert_model(masked_input)\n",
    "\n",
    "        # compute the cross-entropy loss\n",
    "        output_v = output_pred.view(-1, output_pred.shape[-1])\n",
    "        target_v = masked_target.view(-1, 1).squeeze()\n",
    "        loss = loss_fn(output_v, target_v)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(train_dataloader)\n",
    "\n",
    "    # test model\n",
    "    bert_model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch_idx, batch_data in enumerate(test_dataloader):\n",
    "            # infer\n",
    "            masked_input = batch_data['input']\n",
    "            masked_target = batch_data['target']\n",
    "\n",
    "            masked_input = masked_input.to(device)\n",
    "            masked_target = masked_target.to(device)\n",
    "            output_pred = bert_model(masked_input)\n",
    "\n",
    "            # compute the cross-entropy loss\n",
    "            output_v = output_pred.view(-1, output_pred.shape[-1])\n",
    "            target_v = masked_target.view(-1, 1).squeeze()\n",
    "            loss = loss_fn(output_v, target_v)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "        test_loss = test_loss / len(test_dataloader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch + 1} | \"\n",
    "        f\"train_loss: {train_loss:.4f} | \"\n",
    "        f\"test_loss: {test_loss:.4f} | \"\n",
    "        f\"| Δw:, {round(bert_model.embeddings.weight.grad.abs().sum().item(), 3)}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc127cbf",
   "metadata": {},
   "source": [
    "### Training the Model (Iterations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf1ec913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(loader,loader_iter):\n",
    "    try:\n",
    "        batch = next(loader_iter)\n",
    "    except StopIteration:\n",
    "        loader_iter = iter(loader)\n",
    "        batch = next(loader_iter)\n",
    "    return batch, loader_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9db1e850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 0  | loss 5.19  | Δw: 6.936\n",
      "it: 10  | loss 5.18  | Δw: 5.817\n"
     ]
    }
   ],
   "source": [
    "batch_iter = iter(train_dataloader)\n",
    "bert_model.train()\n",
    "print_each = 10\n",
    "\n",
    "for it in range(n_iterations):\n",
    "    # get batch\n",
    "    batch_data, batch_iter = get_batch(train_dataloader, batch_iter)\n",
    "\n",
    "    masked_input = batch_data['input']\n",
    "    masked_target = batch_data['target']\n",
    "\n",
    "    masked_input = masked_input.to(device)\n",
    "    masked_target = masked_target.to(device)\n",
    "    output_pred = bert_model(masked_input)\n",
    "\n",
    "    # compute the cross-entropy loss\n",
    "    output_v = output_pred.view(-1, output_pred.shape[-1])\n",
    "    target_v = masked_target.view(-1, 1).squeeze()\n",
    "    loss = loss_fn(output_v, target_v)\n",
    "\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    # print step\n",
    "    if it % print_each == 0:\n",
    "        print('it:', it,\n",
    "              ' | loss', np.round(loss.item(), 2),\n",
    "              ' | Δw:', round(bert_model.embeddings.weight.grad.abs().sum().item(), 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
